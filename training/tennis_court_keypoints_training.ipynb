{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\n",
      "  0 6919M    0 1978k    0     0   503k      0  3:54:33  0:00:03  3:54:30  503k\n",
      "  0 6919M    0 29.5M    0     0  6137k      0  0:19:14  0:00:04  0:19:10 6139k\n",
      "  0 6919M    0 56.3M    0     0  9739k      0  0:12:07  0:00:05  0:12:02 11.6M\n",
      "  1 6919M    1 84.5M    0     0  12.2M      0  0:09:26  0:00:06  0:09:20 18.3M\n",
      "  1 6919M    1  109M    0     0  13.8M      0  0:08:19  0:00:07  0:08:12 23.8M\n",
      "  2 6919M    2  139M    0     0  15.5M      0  0:07:24  0:00:08  0:07:16 27.4M\n",
      "  2 6919M    2  166M    0     0  16.7M      0  0:06:52  0:00:09  0:06:43 27.3M\n",
      "  2 6919M    2  194M    0     0  17.8M      0  0:06:28  0:00:10  0:06:18 27.6M\n",
      "  3 6919M    3  220M    0     0  18.5M      0  0:06:13  0:00:11  0:06:02 27.2M\n",
      "  3 6919M    3  260M    0     0  20.1M      0  0:05:43  0:00:12  0:05:31 30.0M\n",
      "  4 6919M    4  298M    0     0  21.4M      0  0:05:23  0:00:13  0:05:10 31.8M\n",
      "  4 6919M    4  327M    0     0  21.9M      0  0:05:15  0:00:14  0:05:01 32.2M\n",
      "  5 6919M    5  361M    0     0  22.7M      0  0:05:04  0:00:15  0:04:49 33.3M\n",
      "  5 6919M    5  399M    0     0  23.5M      0  0:04:53  0:00:16  0:04:37 35.6M\n",
      "  6 6919M    6  425M    0     0  23.6M      0  0:04:52  0:00:17  0:04:35 32.8M\n",
      "  6 6919M    6  456M    0     0  24.1M      0  0:04:46  0:00:18  0:04:28 31.7M\n",
      "  7 6919M    7  491M    0     0  24.6M      0  0:04:40  0:00:19  0:04:21 32.6M\n",
      "  7 6919M    7  517M    0     0  24.7M      0  0:04:39  0:00:20  0:04:19 31.0M\n",
      "  8 6919M    8  553M    0     0  25.2M      0  0:04:33  0:00:21  0:04:12 30.9M\n",
      "  8 6919M    8  577M    0     0  25.2M      0  0:04:34  0:00:22  0:04:12 30.7M\n",
      "  8 6919M    8  603M    0     0  25.2M      0  0:04:34  0:00:23  0:04:11 29.2M\n",
      "  9 6919M    9  629M    0     0  25.2M      0  0:04:34  0:00:24  0:04:10 27.5M\n",
      "  9 6919M    9  659M    0     0  25.4M      0  0:04:32  0:00:25  0:04:07 28.4M\n",
      " 10 6919M   10  696M    0     0  25.7M      0  0:04:28  0:00:26  0:04:02 28.1M\n",
      " 10 6919M   10  735M    0     0  26.3M      0  0:04:22  0:00:27  0:03:55 31.4M\n",
      " 11 6919M   11  770M    0     0  26.6M      0  0:04:19  0:00:28  0:03:51 33.5M\n",
      " 11 6919M   11  808M    0     0  27.0M      0  0:04:16  0:00:29  0:03:47 35.9M\n",
      " 12 6919M   12  840M    0     0  27.1M      0  0:04:14  0:00:30  0:03:44 36.1M\n",
      " 12 6919M   12  869M    0     0  27.2M      0  0:04:14  0:00:31  0:03:43 35.0M\n",
      " 12 6919M   12  896M    0     0  27.2M      0  0:04:14  0:00:32  0:03:42 32.2M\n",
      " 13 6919M   13  925M    0     0  27.2M      0  0:04:13  0:00:33  0:03:40 30.8M\n",
      " 13 6919M   13  960M    0     0  27.4M      0  0:04:11  0:00:34  0:03:37 30.2M\n",
      " 14 6919M   14  986M    0     0  27.4M      0  0:04:12  0:00:35  0:03:37 29.1M\n",
      " 14 6919M   14 1005M    0     0  27.2M      0  0:04:14  0:00:36  0:03:38 27.1M\n",
      " 14 6919M   14 1029M    0     0  27.1M      0  0:04:14  0:00:37  0:03:37 26.5M\n",
      " 15 6919M   15 1055M    0     0  27.0M      0  0:04:15  0:00:38  0:03:37 25.7M\n",
      " 15 6919M   15 1079M    0     0  27.0M      0  0:04:15  0:00:39  0:03:36 23.8M\n",
      " 16 6919M   16 1112M    0     0  27.1M      0  0:04:14  0:00:40  0:03:34 25.3M\n",
      " 16 6919M   16 1138M    0     0  27.1M      0  0:04:14  0:00:41  0:03:33 26.6M\n",
      " 16 6919M   16 1168M    0     0  27.2M      0  0:04:14  0:00:42  0:03:32 27.6M\n",
      " 17 6919M   17 1205M    0     0  27.4M      0  0:04:12  0:00:43  0:03:29 30.2M\n",
      " 18 6919M   18 1248M    0     0  27.7M      0  0:04:09  0:00:44  0:03:25 33.7M\n",
      " 18 6919M   18 1278M    0     0  27.8M      0  0:04:08  0:00:45  0:03:23 33.1M\n",
      " 18 6919M   18 1309M    0     0  27.8M      0  0:04:08  0:00:46  0:03:22 34.1M\n",
      " 19 6919M   19 1331M    0     0  27.7M      0  0:04:08  0:00:47  0:03:21 32.7M\n",
      " 19 6919M   19 1358M    0     0  27.7M      0  0:04:09  0:00:48  0:03:21 30.5M\n",
      " 20 6919M   20 1386M    0     0  27.7M      0  0:04:09  0:00:49  0:03:20 27.6M\n",
      " 20 6919M   20 1418M    0     0  27.8M      0  0:04:08  0:00:50  0:03:18 28.0M\n",
      " 21 6919M   21 1458M    0     0  28.0M      0  0:04:06  0:00:51  0:03:15 29.8M\n",
      " 21 6919M   21 1493M    0     0  28.2M      0  0:04:05  0:00:52  0:03:13 32.2M\n",
      " 22 6919M   22 1526M    0     0  28.3M      0  0:04:04  0:00:53  0:03:11 33.7M\n",
      " 22 6919M   22 1549M    0     0  28.2M      0  0:04:05  0:00:54  0:03:11 32.7M\n",
      " 22 6919M   22 1579M    0     0  28.2M      0  0:04:05  0:00:55  0:03:10 32.0M\n",
      " 23 6919M   23 1617M    0     0  28.4M      0  0:04:03  0:00:56  0:03:07 31.8M\n",
      " 23 6919M   23 1644M    0     0  28.3M      0  0:04:03  0:00:57  0:03:06 30.1M\n",
      " 24 6919M   24 1683M    0     0  28.5M      0  0:04:02  0:00:58  0:03:04 31.4M\n",
      " 24 6919M   24 1725M    0     0  28.7M      0  0:04:00  0:00:59  0:03:01 35.2M\n",
      " 25 6919M   25 1760M    0     0  28.8M      0  0:03:59  0:01:00  0:02:59 36.2M\n",
      " 25 6919M   25 1788M    0     0  28.8M      0  0:03:59  0:01:01  0:02:58 34.0M\n",
      " 26 6919M   26 1824M    0     0  28.9M      0  0:03:58  0:01:02  0:02:56 36.0M\n",
      " 26 6919M   26 1854M    0     0  29.0M      0  0:03:58  0:01:03  0:02:55 34.0M\n",
      " 27 6919M   27 1880M    0     0  28.9M      0  0:03:58  0:01:04  0:02:54 30.9M\n",
      " 27 6919M   27 1908M    0     0  28.9M      0  0:03:59  0:01:05  0:02:54 29.6M\n",
      " 27 6919M   27 1928M    0     0  28.7M      0  0:04:00  0:01:07  0:02:53 26.9M\n",
      " 28 6919M   28 1948M    0     0  28.6M      0  0:04:01  0:01:08  0:02:53 24.0M\n",
      " 28 6919M   28 1966M    0     0  28.5M      0  0:04:02  0:01:08  0:02:54 22.2M\n",
      " 28 6919M   28 1986M    0     0  28.4M      0  0:04:03  0:01:09  0:02:54 21.1M\n",
      " 29 6919M   29 2010M    0     0  28.3M      0  0:04:04  0:01:10  0:02:54 20.4M\n",
      " 29 6919M   29 2038M    0     0  28.3M      0  0:04:04  0:01:11  0:02:53 22.8M\n",
      " 29 6919M   29 2057M    0     0  28.2M      0  0:04:05  0:01:12  0:02:53 22.6M\n",
      " 30 6919M   30 2083M    0     0  28.0M      0  0:04:06  0:01:14  0:02:52 22.5M\n",
      " 30 6919M   30 2106M    0     0  28.1M      0  0:04:06  0:01:14  0:02:52 23.9M\n",
      " 30 6919M   30 2130M    0     0  28.0M      0  0:04:06  0:01:15  0:02:51 23.8M\n",
      " 31 6919M   31 2156M    0     0  28.0M      0  0:04:06  0:01:16  0:02:50 23.7M\n",
      " 31 6919M   31 2181M    0     0  27.9M      0  0:04:07  0:01:17  0:02:50 24.5M\n",
      " 31 6919M   31 2200M    0     0  27.8M      0  0:04:08  0:01:18  0:02:50 24.3M\n",
      " 32 6919M   32 2226M    0     0  27.8M      0  0:04:08  0:01:19  0:02:49 24.0M\n",
      " 32 6919M   32 2251M    0     0  27.8M      0  0:04:08  0:01:20  0:02:48 24.3M\n",
      " 32 6919M   32 2270M    0     0  27.7M      0  0:04:09  0:01:21  0:02:48 22.7M\n",
      " 33 6919M   33 2299M    0     0  27.7M      0  0:04:09  0:01:22  0:02:47 23.6M\n",
      " 33 6919M   33 2319M    0     0  27.6M      0  0:04:10  0:01:23  0:02:47 23.8M\n",
      " 33 6919M   33 2343M    0     0  27.5M      0  0:04:10  0:01:24  0:02:46 23.4M\n",
      " 34 6919M   34 2368M    0     0  27.5M      0  0:04:11  0:01:25  0:02:46 23.2M\n",
      " 34 6919M   34 2394M    0     0  27.5M      0  0:04:11  0:01:26  0:02:45 24.9M\n",
      " 35 6919M   35 2423M    0     0  27.5M      0  0:04:11  0:01:27  0:02:44 24.7M\n",
      " 35 6919M   35 2446M    0     0  27.5M      0  0:04:11  0:01:28  0:02:43 25.4M\n",
      " 35 6919M   35 2473M    0     0  27.5M      0  0:04:11  0:01:29  0:02:42 25.9M\n",
      " 36 6919M   36 2500M    0     0  27.4M      0  0:04:11  0:01:30  0:02:41 26.4M\n",
      " 36 6919M   36 2521M    0     0  27.4M      0  0:04:12  0:01:31  0:02:41 25.2M\n",
      " 36 6919M   36 2548M    0     0  27.3M      0  0:04:12  0:01:33  0:02:39 24.1M\n",
      " 36 6919M   36 2560M    0     0  27.2M      0  0:04:14  0:01:33  0:02:41 22.4M\n",
      " 37 6919M   37 2592M    0     0  27.3M      0  0:04:13  0:01:34  0:02:39 23.8M\n",
      " 37 6919M   37 2627M    0     0  27.3M      0  0:04:12  0:01:35  0:02:37 25.3M\n",
      " 38 6919M   38 2659M    0     0  27.4M      0  0:04:12  0:01:36  0:02:36 27.6M\n",
      " 38 6919M   38 2694M    0     0  27.5M      0  0:04:11  0:01:37  0:02:34 30.4M\n",
      " 39 6919M   39 2730M    0     0  27.6M      0  0:04:10  0:01:38  0:02:32 34.5M\n",
      " 39 6919M   39 2748M    0     0  27.5M      0  0:04:11  0:01:39  0:02:32 31.0M\n",
      " 40 6919M   40 2777M    0     0  27.5M      0  0:04:11  0:01:40  0:02:31 30.1M\n",
      " 40 6919M   40 2804M    0     0  27.4M      0  0:04:11  0:01:42  0:02:29 28.5M\n",
      " 40 6919M   40 2821M    0     0  27.4M      0  0:04:12  0:01:42  0:02:30 25.4M\n",
      " 41 6919M   41 2852M    0     0  27.4M      0  0:04:12  0:01:43  0:02:29 24.2M\n",
      " 41 6919M   41 2865M    0     0  27.3M      0  0:04:13  0:01:44  0:02:29 23.5M\n",
      " 41 6919M   41 2892M    0     0  27.3M      0  0:04:13  0:01:45  0:02:28 22.9M\n",
      " 42 6919M   42 2919M    0     0  27.3M      0  0:04:13  0:01:46  0:02:27 23.3M\n",
      " 42 6919M   42 2947M    0     0  27.3M      0  0:04:13  0:01:47  0:02:26 25.1M\n",
      " 42 6919M   42 2974M    0     0  27.3M      0  0:04:13  0:01:48  0:02:25 24.4M\n",
      " 43 6919M   43 3005M    0     0  27.3M      0  0:04:13  0:01:49  0:02:24 27.9M\n",
      " 43 6919M   43 3035M    0     0  27.3M      0  0:04:12  0:01:50  0:02:22 28.5M\n",
      " 44 6919M   44 3065M    0     0  27.3M      0  0:04:12  0:01:51  0:02:21 28.8M\n",
      " 44 6919M   44 3090M    0     0  27.3M      0  0:04:12  0:01:52  0:02:20 28.5M\n",
      " 45 6919M   45 3117M    0     0  27.3M      0  0:04:12  0:01:53  0:02:19 28.6M\n",
      " 45 6919M   45 3146M    0     0  27.3M      0  0:04:12  0:01:54  0:02:18 28.1M\n",
      " 45 6919M   45 3167M    0     0  27.3M      0  0:04:13  0:01:55  0:02:18 26.3M\n",
      " 46 6919M   46 3191M    0     0  27.2M      0  0:04:13  0:01:57  0:02:16 24.6M\n",
      " 46 6919M   46 3214M    0     0  27.2M      0  0:04:13  0:01:57  0:02:16 24.7M\n",
      " 46 6919M   46 3232M    0     0  27.1M      0  0:04:14  0:01:58  0:02:16 22.9M\n",
      " 47 6919M   47 3254M    0     0  27.1M      0  0:04:15  0:01:59  0:02:16 21.5M\n",
      " 47 6919M   47 3292M    0     0  27.2M      0  0:04:14  0:02:00  0:02:14 25.0M\n",
      " 48 6919M   48 3328M    0     0  27.2M      0  0:04:13  0:02:01  0:02:12 28.3M\n",
      " 48 6919M   48 3365M    0     0  27.3M      0  0:04:12  0:02:02  0:02:10 30.1M\n",
      " 49 6919M   49 3394M    0     0  27.3M      0  0:04:12  0:02:03  0:02:09 32.2M\n",
      " 49 6919M   49 3421M    0     0  27.3M      0  0:04:12  0:02:04  0:02:08 33.4M\n",
      " 49 6919M   49 3450M    0     0  27.4M      0  0:04:12  0:02:05  0:02:07 31.6M\n",
      " 50 6919M   50 3472M    0     0  27.3M      0  0:04:13  0:02:07  0:02:06 28.2M\n",
      " 50 6919M   50 3494M    0     0  27.3M      0  0:04:13  0:02:07  0:02:06 25.9M\n",
      " 50 6919M   50 3522M    0     0  27.2M      0  0:04:13  0:02:09  0:02:04 25.1M\n",
      " 51 6919M   51 3540M    0     0  27.2M      0  0:04:13  0:02:09  0:02:04 23.8M\n",
      " 51 6919M   51 3565M    0     0  27.2M      0  0:04:14  0:02:11  0:02:03 22.5M\n",
      " 51 6919M   51 3585M    0     0  27.1M      0  0:04:14  0:02:12  0:02:02 22.5M\n",
      " 52 6919M   52 3605M    0     0  27.1M      0  0:04:15  0:02:12  0:02:03 22.2M\n",
      " 52 6919M   52 3623M    0     0  27.0M      0  0:04:15  0:02:13  0:02:02 20.6M\n",
      " 52 6919M   52 3650M    0     0  27.0M      0  0:04:15  0:02:14  0:02:01 21.8M\n",
      " 53 6919M   53 3684M    0     0  27.1M      0  0:04:15  0:02:15  0:02:00 24.2M\n",
      " 53 6919M   53 3714M    0     0  27.1M      0  0:04:15  0:02:16  0:01:59 26.4M\n",
      " 54 6919M   54 3743M    0     0  27.1M      0  0:04:14  0:02:17  0:01:57 27.5M\n",
      " 54 6919M   54 3777M    0     0  27.1M      0  0:04:14  0:02:18  0:01:56 30.7M\n",
      " 54 6919M   54 3803M    0     0  27.1M      0  0:04:14  0:02:20  0:01:54 29.8M\n",
      " 55 6919M   55 3834M    0     0  27.2M      0  0:04:14  0:02:20  0:01:54 29.8M\n",
      " 55 6919M   55 3856M    0     0  27.1M      0  0:04:14  0:02:21  0:01:53 28.2M\n",
      " 56 6919M   56 3879M    0     0  27.1M      0  0:04:14  0:02:22  0:01:52 27.1M\n",
      " 56 6919M   56 3908M    0     0  27.1M      0  0:04:15  0:02:24  0:01:51 25.5M\n",
      " 56 6919M   56 3934M    0     0  27.1M      0  0:04:14  0:02:24  0:01:50 26.9M\n",
      " 57 6919M   57 3959M    0     0  27.1M      0  0:04:15  0:02:25  0:01:50 25.0M\n",
      " 57 6919M   57 3989M    0     0  27.1M      0  0:04:15  0:02:27  0:01:48 26.0M\n",
      " 58 6919M   58 4017M    0     0  27.1M      0  0:04:14  0:02:27  0:01:47 27.5M\n",
      " 58 6919M   58 4050M    0     0  27.1M      0  0:04:14  0:02:29  0:01:45 28.1M\n",
      " 58 6919M   58 4071M    0     0  27.1M      0  0:04:14  0:02:29  0:01:45 27.3M\n",
      " 59 6919M   59 4104M    0     0  27.1M      0  0:04:14  0:02:30  0:01:44 28.7M\n",
      " 59 6919M   59 4130M    0     0  27.1M      0  0:04:14  0:02:31  0:01:43 28.8M\n",
      " 59 6919M   59 4145M    0     0  27.1M      0  0:04:15  0:02:32  0:01:43 25.6M\n",
      " 60 6919M   60 4176M    0     0  27.1M      0  0:04:15  0:02:33  0:01:42 26.1M\n",
      " 60 6919M   60 4201M    0     0  27.1M      0  0:04:15  0:02:35  0:01:40 25.5M\n",
      " 61 6919M   61 4225M    0     0  27.1M      0  0:04:15  0:02:35  0:01:40 24.4M\n",
      " 61 6919M   61 4251M    0     0  27.0M      0  0:04:15  0:02:36  0:01:39 24.2M\n",
      " 61 6919M   61 4275M    0     0  27.0M      0  0:04:15  0:02:37  0:01:38 26.0M\n",
      " 62 6919M   62 4304M    0     0  27.0M      0  0:04:15  0:02:39  0:01:36 25.0M\n",
      " 62 6919M   62 4327M    0     0  27.0M      0  0:04:15  0:02:39  0:01:36 25.6M\n",
      " 62 6919M   62 4358M    0     0  27.0M      0  0:04:15  0:02:40  0:01:35 26.5M\n",
      " 63 6919M   63 4380M    0     0  27.0M      0  0:04:15  0:02:41  0:01:34 25.8M\n",
      " 63 6919M   63 4404M    0     0  27.0M      0  0:04:16  0:02:43  0:01:33 25.0M\n",
      " 64 6919M   64 4436M    0     0  27.0M      0  0:04:15  0:02:43  0:01:32 26.9M\n",
      " 64 6919M   64 4472M    0     0  27.1M      0  0:04:15  0:02:44  0:01:31 28.9M\n",
      " 65 6919M   65 4501M    0     0  27.1M      0  0:04:15  0:02:45  0:01:30 28.4M\n",
      " 65 6919M   65 4538M    0     0  27.1M      0  0:04:14  0:02:46  0:01:28 31.6M\n",
      " 66 6919M   66 4570M    0     0  27.2M      0  0:04:14  0:02:47  0:01:27 34.2M\n",
      " 66 6919M   66 4608M    0     0  27.2M      0  0:04:14  0:02:49  0:01:25 32.5M\n",
      " 66 6919M   66 4609M    0     0  27.0M      0  0:04:15  0:02:50  0:01:25 25.9M\n",
      " 67 6919M   67 4636M    0     0  27.1M      0  0:04:15  0:02:50  0:01:25 27.1M\n",
      " 67 6919M   67 4666M    0     0  27.1M      0  0:04:14  0:02:51  0:01:23 25.7M\n",
      " 67 6919M   67 4693M    0     0  27.1M      0  0:04:14  0:02:52  0:01:22 24.4M\n",
      " 68 6919M   68 4734M    0     0  27.2M      0  0:04:14  0:02:53  0:01:21 26.6M\n",
      " 69 6919M   69 4780M    0     0  27.3M      0  0:04:13  0:02:54  0:01:19 36.2M\n",
      " 69 6919M   69 4816M    0     0  27.3M      0  0:04:12  0:02:55  0:01:17 35.5M\n",
      " 69 6919M   69 4838M    0     0  27.3M      0  0:04:13  0:02:56  0:01:17 33.7M\n",
      " 70 6919M   70 4860M    0     0  27.3M      0  0:04:13  0:02:57  0:01:16 33.2M\n",
      " 70 6919M   70 4881M    0     0  27.2M      0  0:04:13  0:02:58  0:01:15 29.4M\n",
      " 70 6919M   70 4905M    0     0  27.2M      0  0:04:13  0:02:59  0:01:14 24.7M\n",
      " 71 6919M   71 4929M    0     0  27.2M      0  0:04:14  0:03:00  0:01:14 22.7M\n",
      " 71 6919M   71 4957M    0     0  27.2M      0  0:04:13  0:03:01  0:01:12 24.2M\n",
      " 72 6919M   72 4986M    0     0  27.2M      0  0:04:13  0:03:02  0:01:11 25.4M\n",
      " 72 6919M   72 5017M    0     0  27.2M      0  0:04:13  0:03:03  0:01:10 27.1M\n",
      " 72 6919M   72 5048M    0     0  27.2M      0  0:04:13  0:03:04  0:01:09 28.7M\n",
      " 73 6919M   73 5069M    0     0  27.2M      0  0:04:13  0:03:05  0:01:08 28.1M\n",
      " 73 6919M   73 5092M    0     0  27.2M      0  0:04:14  0:03:07  0:01:07 26.1M\n",
      " 73 6919M   73 5112M    0     0  27.2M      0  0:04:14  0:03:07  0:01:07 25.1M\n",
      " 74 6919M   74 5134M    0     0  27.1M      0  0:04:14  0:03:08  0:01:06 23.4M\n",
      " 74 6919M   74 5158M    0     0  27.1M      0  0:04:14  0:03:09  0:01:05 22.0M\n",
      " 74 6919M   74 5181M    0     0  27.1M      0  0:04:15  0:03:10  0:01:05 22.1M\n",
      " 75 6919M   75 5203M    0     0  27.1M      0  0:04:15  0:03:11  0:01:04 22.9M\n",
      " 75 6919M   75 5216M    0     0  27.0M      0  0:04:15  0:03:12  0:01:03 20.7M\n",
      " 75 6919M   75 5233M    0     0  26.9M      0  0:04:16  0:03:13  0:01:03 19.8M\n",
      " 75 6919M   75 5251M    0     0  26.9M      0  0:04:16  0:03:14  0:01:02 18.5M\n",
      " 76 6919M   76 5277M    0     0  26.9M      0  0:04:16  0:03:15  0:01:01 19.3M\n",
      " 76 6919M   76 5297M    0     0  26.8M      0  0:04:17  0:03:17  0:01:00 18.3M\n",
      " 76 6919M   76 5323M    0     0  26.8M      0  0:04:17  0:03:17  0:01:00 21.4M\n",
      " 77 6919M   77 5348M    0     0  26.8M      0  0:04:17  0:03:18  0:00:59 22.9M\n",
      " 77 6919M   77 5370M    0     0  26.8M      0  0:04:17  0:03:19  0:00:58 23.7M\n",
      " 77 6919M   77 5396M    0     0  26.8M      0  0:04:17  0:03:20  0:00:57 23.6M\n",
      " 78 6919M   78 5422M    0     0  26.8M      0  0:04:17  0:03:21  0:00:56 25.4M\n",
      " 78 6919M   78 5456M    0     0  26.8M      0  0:04:17  0:03:22  0:00:55 26.4M\n",
      " 79 6919M   79 5481M    0     0  26.8M      0  0:04:17  0:03:23  0:00:54 26.5M\n",
      " 79 6919M   79 5516M    0     0  26.9M      0  0:04:17  0:03:24  0:00:53 29.3M\n",
      " 80 6919M   80 5547M    0     0  26.9M      0  0:04:16  0:03:25  0:00:51 30.4M\n",
      " 80 6919M   80 5581M    0     0  26.9M      0  0:04:16  0:03:26  0:00:50 31.8M\n",
      " 81 6919M   81 5620M    0     0  27.0M      0  0:04:15  0:03:27  0:00:48 32.9M\n",
      " 81 6919M   81 5659M    0     0  27.0M      0  0:04:15  0:03:28  0:00:47 35.5M\n",
      " 82 6919M   82 5690M    0     0  27.1M      0  0:04:15  0:03:29  0:00:46 34.7M\n",
      " 82 6919M   82 5719M    0     0  27.1M      0  0:04:15  0:03:30  0:00:45 34.3M\n",
      " 83 6919M   83 5749M    0     0  27.1M      0  0:04:15  0:03:31  0:00:44 33.4M\n",
      " 83 6919M   83 5777M    0     0  27.1M      0  0:04:15  0:03:32  0:00:43 31.3M\n",
      " 83 6919M   83 5804M    0     0  27.1M      0  0:04:15  0:03:33  0:00:42 28.9M\n",
      " 84 6919M   84 5835M    0     0  27.1M      0  0:04:14  0:03:34  0:00:40 28.9M\n",
      " 84 6919M   84 5871M    0     0  27.1M      0  0:04:14  0:03:35  0:00:39 30.3M\n",
      " 85 6919M   85 5901M    0     0  27.2M      0  0:04:14  0:03:36  0:00:38 30.5M\n",
      " 85 6919M   85 5934M    0     0  27.2M      0  0:04:14  0:03:37  0:00:37 31.4M\n",
      " 86 6919M   86 5967M    0     0  27.2M      0  0:04:13  0:03:38  0:00:35 32.7M\n",
      " 86 6919M   86 5995M    0     0  27.2M      0  0:04:13  0:03:39  0:00:34 31.9M\n",
      " 87 6919M   87 6032M    0     0  27.3M      0  0:04:13  0:03:40  0:00:33 31.9M\n",
      " 87 6919M   87 6070M    0     0  27.3M      0  0:04:12  0:03:41  0:00:31 33.7M\n",
      " 88 6919M   88 6112M    0     0  27.4M      0  0:04:12  0:03:42  0:00:30 35.5M\n",
      " 88 6919M   88 6145M    0     0  27.4M      0  0:04:12  0:03:43  0:00:29 35.5M\n",
      " 89 6919M   89 6185M    0     0  27.4M      0  0:04:11  0:03:44  0:00:27 37.9M\n",
      " 89 6919M   89 6226M    0     0  27.5M      0  0:04:11  0:03:45  0:00:26 39.0M\n",
      " 90 6919M   90 6266M    0     0  27.6M      0  0:04:10  0:03:46  0:00:24 39.2M\n",
      " 90 6919M   90 6289M    0     0  27.5M      0  0:04:10  0:03:47  0:00:23 35.3M\n",
      " 91 6919M   91 6319M    0     0  27.6M      0  0:04:10  0:03:48  0:00:22 34.8M\n",
      " 91 6919M   91 6351M    0     0  27.6M      0  0:04:10  0:03:49  0:00:21 33.1M\n",
      " 92 6919M   92 6384M    0     0  27.6M      0  0:04:10  0:03:50  0:00:20 31.6M\n",
      " 92 6919M   92 6423M    0     0  27.6M      0  0:04:09  0:03:51  0:00:18 31.4M\n",
      " 93 6919M   93 6462M    0     0  27.7M      0  0:04:09  0:03:53  0:00:16 33.2M\n",
      " 93 6919M   93 6483M    0     0  27.7M      0  0:04:09  0:03:53  0:00:16 32.7M\n",
      " 94 6919M   94 6519M    0     0  27.7M      0  0:04:09  0:03:54  0:00:15 33.7M\n",
      " 94 6919M   94 6544M    0     0  27.7M      0  0:04:09  0:03:55  0:00:14 31.7M\n",
      " 94 6919M   94 6564M    0     0  27.7M      0  0:04:09  0:03:56  0:00:13 28.2M\n",
      " 95 6919M   95 6580M    0     0  27.6M      0  0:04:10  0:03:57  0:00:13 24.5M\n",
      " 95 6919M   95 6608M    0     0  27.6M      0  0:04:10  0:03:58  0:00:12 24.9M\n",
      " 95 6919M   95 6638M    0     0  27.6M      0  0:04:10  0:03:59  0:00:11 23.6M\n",
      " 96 6919M   96 6651M    0     0  27.6M      0  0:04:10  0:04:00  0:00:10 21.6M\n",
      " 96 6919M   96 6688M    0     0  27.6M      0  0:04:10  0:04:01  0:00:09 24.6M\n",
      " 97 6919M   97 6722M    0     0  27.6M      0  0:04:10  0:04:02  0:00:08 28.4M\n",
      " 97 6919M   97 6751M    0     0  27.6M      0  0:04:09  0:04:03  0:00:06 28.6M\n",
      " 97 6919M   97 6773M    0     0  27.6M      0  0:04:10  0:04:04  0:00:06 27.0M\n",
      " 98 6919M   98 6804M    0     0  27.6M      0  0:04:10  0:04:05  0:00:05 30.4M\n",
      " 98 6919M   98 6833M    0     0  27.6M      0  0:04:10  0:04:06  0:00:04 29.1M\n",
      " 99 6919M   99 6853M    0     0  27.6M      0  0:04:10  0:04:07  0:00:03 26.1M\n",
      " 99 6919M   99 6885M    0     0  27.6M      0  0:04:10  0:04:09  0:00:01 25.9M\n",
      " 99 6919M   99 6909M    0     0  27.6M      0  0:04:10  0:04:09  0:00:01 27.1M\n",
      "100 6919M  100 6919M    0     0  27.6M      0  0:04:10  0:04:10 --:--:-- 26.7M\n"
     ]
    }
   ],
   "source": [
    "# Download from Google Drive\n",
    "!curl -L -o tennis_court_det_dataset.zip \"https://drive.usercontent.google.com/download?id=1lhAaeQCmk2y440PmagA0KmIVBIysVMwu&export=download&authuser=0&confirm=t&uuid=3077628e-fc9b-4ef2-8cde-b291040afb30&at=APZUnTU9lSikCSe3NqbxV5MVad5T%3A1708243355040\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Unzip the data\n",
    "!unzip tennis_court_det_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(data_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n",
    "        h,w = img.shape[:2]\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transforms(img)\n",
    "        kps = np.array(item['kps']).flatten()\n",
    "        kps = kps.astype(np.float32)\n",
    "\n",
    "        kps[::2] *= 224.0 / w \n",
    "        kps[1::2] *= 224.0 / h \n",
    "\n",
    "        return img, kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(\"tennis_court_det_dataset/data/images\",\"tennis_court_det_dataset/data/data_train.json\")\n",
    "val_dataset = KeypointsDataset(\"tennis_court_det_dataset/data/images\",\"tennis_court_det_dataset/data/data_val.json\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arjun\\OneDrive\\Documents\\Visual Studio 2022\\Python\\Project_Tennis\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\arjun\\OneDrive\\Documents\\Visual Studio 2022\\Python\\Project_Tennis\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc =  torch.nn.Linear(model.fc.in_features, 14*2) # Replaces the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss: 11056.982421875\n",
      "Epoch 0, iter 10, loss: 10463.5185546875\n",
      "Epoch 0, iter 20, loss: 10024.4091796875\n",
      "Epoch 0, iter 30, loss: 10430.1943359375\n",
      "Epoch 0, iter 40, loss: 9619.4404296875\n",
      "Epoch 0, iter 50, loss: 8940.126953125\n",
      "Epoch 0, iter 60, loss: 8625.4287109375\n",
      "Epoch 0, iter 70, loss: 9088.9404296875\n",
      "Epoch 0, iter 80, loss: 8128.88037109375\n",
      "Epoch 0, iter 90, loss: 7791.2646484375\n",
      "Epoch 0, iter 100, loss: 7659.5205078125\n",
      "Epoch 0, iter 110, loss: 8142.58154296875\n",
      "Epoch 0, iter 120, loss: 6366.09912109375\n",
      "Epoch 0, iter 130, loss: 8089.1279296875\n",
      "Epoch 0, iter 140, loss: 6512.33447265625\n",
      "Epoch 0, iter 150, loss: 5754.71630859375\n",
      "Epoch 0, iter 160, loss: 6205.08203125\n",
      "Epoch 0, iter 170, loss: 5741.7236328125\n",
      "Epoch 0, iter 180, loss: 5566.11279296875\n",
      "Epoch 0, iter 190, loss: 5568.7880859375\n",
      "Epoch 0, iter 200, loss: 5081.13037109375\n",
      "Epoch 0, iter 210, loss: 4728.57470703125\n",
      "Epoch 0, iter 220, loss: 4588.61865234375\n",
      "Epoch 0, iter 230, loss: 4387.7939453125\n",
      "Epoch 0, iter 240, loss: 4023.12353515625\n",
      "Epoch 0, iter 250, loss: 4175.83984375\n",
      "Epoch 0, iter 260, loss: 4024.044921875\n",
      "Epoch 0, iter 270, loss: 3427.208984375\n",
      "Epoch 0, iter 280, loss: 4066.647216796875\n",
      "Epoch 0, iter 290, loss: 3572.85986328125\n",
      "Epoch 0, iter 300, loss: 3435.50439453125\n",
      "Epoch 0, iter 310, loss: 2918.560302734375\n",
      "Epoch 0, iter 320, loss: 2602.815185546875\n",
      "Epoch 0, iter 330, loss: 2700.170166015625\n",
      "Epoch 0, iter 340, loss: 2844.112060546875\n",
      "Epoch 0, iter 350, loss: 2629.264404296875\n",
      "Epoch 0, iter 360, loss: 2216.89111328125\n",
      "Epoch 0, iter 370, loss: 2420.82470703125\n",
      "Epoch 0, iter 380, loss: 2174.876953125\n",
      "Epoch 0, iter 390, loss: 1924.6815185546875\n",
      "Epoch 0, iter 400, loss: 2257.42431640625\n",
      "Epoch 0, iter 410, loss: 1668.4735107421875\n",
      "Epoch 0, iter 420, loss: 1695.3077392578125\n",
      "Epoch 0, iter 430, loss: 1428.1778564453125\n",
      "Epoch 0, iter 440, loss: 1777.812255859375\n",
      "Epoch 0, iter 450, loss: 1411.995849609375\n",
      "Epoch 0, iter 460, loss: 1260.0244140625\n",
      "Epoch 0, iter 470, loss: 1270.328125\n",
      "Epoch 0, iter 480, loss: 1557.163330078125\n",
      "Epoch 0, iter 490, loss: 1214.7379150390625\n",
      "Epoch 0, iter 500, loss: 1086.512939453125\n",
      "Epoch 0, iter 510, loss: 957.2919311523438\n",
      "Epoch 0, iter 520, loss: 997.0729370117188\n",
      "Epoch 0, iter 530, loss: 934.8764038085938\n",
      "Epoch 0, iter 540, loss: 1000.4485473632812\n",
      "Epoch 0, iter 550, loss: 928.6892700195312\n",
      "Epoch 0, iter 560, loss: 584.296142578125\n",
      "Epoch 0, iter 570, loss: 770.1179809570312\n",
      "Epoch 0, iter 580, loss: 636.0157470703125\n",
      "Epoch 0, iter 590, loss: 610.4747314453125\n",
      "Epoch 0, iter 600, loss: 468.03277587890625\n",
      "Epoch 0, iter 610, loss: 520.7711791992188\n",
      "Epoch 0, iter 620, loss: 484.92333984375\n",
      "Epoch 0, iter 630, loss: 428.7771301269531\n",
      "Epoch 0, iter 640, loss: 496.7008972167969\n",
      "Epoch 0, iter 650, loss: 516.72021484375\n",
      "Epoch 0, iter 660, loss: 360.8951721191406\n",
      "Epoch 0, iter 670, loss: 346.05316162109375\n",
      "Epoch 0, iter 680, loss: 271.4949035644531\n",
      "Epoch 0, iter 690, loss: 329.5952453613281\n",
      "Epoch 0, iter 700, loss: 261.9590759277344\n",
      "Epoch 0, iter 710, loss: 283.0284118652344\n",
      "Epoch 0, iter 720, loss: 249.56283569335938\n",
      "Epoch 0, iter 730, loss: 243.63442993164062\n",
      "Epoch 0, iter 740, loss: 220.36634826660156\n",
      "Epoch 0, iter 750, loss: 182.4940185546875\n",
      "Epoch 0, iter 760, loss: 212.80357360839844\n",
      "Epoch 0, iter 770, loss: 252.27394104003906\n",
      "Epoch 0, iter 780, loss: 147.06871032714844\n",
      "Epoch 0, iter 790, loss: 186.75624084472656\n",
      "Epoch 0, iter 800, loss: 130.01181030273438\n",
      "Epoch 0, iter 810, loss: 239.94869995117188\n",
      "Epoch 0, iter 820, loss: 114.58616638183594\n",
      "Epoch 1, iter 0, loss: 85.0298843383789\n",
      "Epoch 1, iter 10, loss: 126.71392822265625\n",
      "Epoch 1, iter 20, loss: 139.6264190673828\n",
      "Epoch 1, iter 30, loss: 99.62310791015625\n",
      "Epoch 1, iter 40, loss: 130.64309692382812\n",
      "Epoch 1, iter 50, loss: 87.7375717163086\n",
      "Epoch 1, iter 60, loss: 80.72509002685547\n",
      "Epoch 1, iter 70, loss: 109.59684753417969\n",
      "Epoch 1, iter 80, loss: 64.99340057373047\n",
      "Epoch 1, iter 90, loss: 45.89263916015625\n",
      "Epoch 1, iter 100, loss: 53.328269958496094\n",
      "Epoch 1, iter 110, loss: 51.20596694946289\n",
      "Epoch 1, iter 120, loss: 281.28399658203125\n",
      "Epoch 1, iter 130, loss: 99.17584228515625\n",
      "Epoch 1, iter 140, loss: 48.28169631958008\n",
      "Epoch 1, iter 150, loss: 38.03670883178711\n",
      "Epoch 1, iter 160, loss: 93.19532012939453\n",
      "Epoch 1, iter 170, loss: 73.46891021728516\n",
      "Epoch 1, iter 180, loss: 30.503314971923828\n",
      "Epoch 1, iter 190, loss: 616.12646484375\n",
      "Epoch 1, iter 200, loss: 49.225608825683594\n",
      "Epoch 1, iter 210, loss: 69.72505187988281\n",
      "Epoch 1, iter 220, loss: 136.41590881347656\n",
      "Epoch 1, iter 230, loss: 41.455074310302734\n",
      "Epoch 1, iter 240, loss: 53.99356460571289\n",
      "Epoch 1, iter 250, loss: 40.5970458984375\n",
      "Epoch 1, iter 260, loss: 27.592626571655273\n",
      "Epoch 1, iter 270, loss: 49.96409225463867\n",
      "Epoch 1, iter 280, loss: 72.81643676757812\n",
      "Epoch 1, iter 290, loss: 21.818172454833984\n",
      "Epoch 1, iter 300, loss: 55.71675491333008\n",
      "Epoch 1, iter 310, loss: 31.184009552001953\n",
      "Epoch 1, iter 320, loss: 49.59897994995117\n",
      "Epoch 1, iter 330, loss: 41.31238555908203\n",
      "Epoch 1, iter 340, loss: 44.469390869140625\n",
      "Epoch 1, iter 350, loss: 36.873931884765625\n",
      "Epoch 1, iter 360, loss: 44.26679229736328\n",
      "Epoch 1, iter 370, loss: 38.58197021484375\n",
      "Epoch 1, iter 380, loss: 26.583372116088867\n",
      "Epoch 1, iter 390, loss: 31.435544967651367\n",
      "Epoch 1, iter 400, loss: 57.37458038330078\n",
      "Epoch 1, iter 410, loss: 40.1955680847168\n",
      "Epoch 1, iter 420, loss: 64.8054428100586\n",
      "Epoch 1, iter 430, loss: 113.80195617675781\n",
      "Epoch 1, iter 440, loss: 64.25834655761719\n",
      "Epoch 1, iter 450, loss: 34.78269958496094\n",
      "Epoch 1, iter 460, loss: 56.74427032470703\n",
      "Epoch 1, iter 470, loss: 60.72996139526367\n",
      "Epoch 1, iter 480, loss: 31.16058349609375\n",
      "Epoch 1, iter 490, loss: 36.666812896728516\n",
      "Epoch 1, iter 500, loss: 47.40941619873047\n",
      "Epoch 1, iter 510, loss: 35.833003997802734\n",
      "Epoch 1, iter 520, loss: 72.63636779785156\n",
      "Epoch 1, iter 530, loss: 25.567047119140625\n",
      "Epoch 1, iter 540, loss: 39.46912384033203\n",
      "Epoch 1, iter 550, loss: 18.937143325805664\n",
      "Epoch 1, iter 560, loss: 92.75811767578125\n",
      "Epoch 1, iter 570, loss: 91.75340270996094\n",
      "Epoch 1, iter 580, loss: 29.284820556640625\n",
      "Epoch 1, iter 590, loss: 125.18627166748047\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m outputs = model(imgs)\n\u001b[32m      9\u001b[39m loss = criterion(outputs, kps)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m optimizer.step()\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arjun\\OneDrive\\Documents\\Visual Studio 2022\\Python\\Project_Tennis\\.venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arjun\\OneDrive\\Documents\\Visual Studio 2022\\Python\\Project_Tennis\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arjun\\OneDrive\\Documents\\Visual Studio 2022\\Python\\Project_Tennis\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs,kps) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        kps = kps.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"keypoints_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
